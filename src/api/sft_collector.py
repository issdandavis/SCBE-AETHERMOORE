"""
SCBE-AETHERMOORE SFT Training Data Collector
==============================================

Thread-safe collector for Supervised Fine-Tuning (SFT) training records
generated by all SaaS API operations — browser automation, fleet dispatch,
knowledge ingestion, safety scans, etc.

Records are written in JSONL (one JSON object per line) to an append-only
log file.  The file auto-rotates at a configurable size threshold.

Usage:
    from src.api.sft_collector import sft_collector

    sft_collector.capture(
        instruction="Navigate to https://example.com",
        response="Navigated to https://example.com (200 OK).",
        category="browser-automation",
        metadata={"tenant": "acme", "session_id": "s-123"},
    )
"""

from __future__ import annotations

import json
import os
import threading
import time
import uuid
from pathlib import Path
from typing import Any, Dict, List, Optional


# ---------------------------------------------------------------------------
#  Default paths
# ---------------------------------------------------------------------------

_PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
DEFAULT_OUTPUT_DIR = os.path.join(_PROJECT_ROOT, "training-data")
DEFAULT_FILENAME = "sft_saas_live.jsonl"

# Auto-rotate at 10 MB
DEFAULT_MAX_SIZE_BYTES = 10 * 1024 * 1024  # 10 MB


# ---------------------------------------------------------------------------
#  SFTCollector
# ---------------------------------------------------------------------------

class SFTCollector:
    """Thread-safe JSONL collector for SFT training records.

    Parameters
    ----------
    output_dir : str
        Directory to write JSONL files to.
    filename : str
        Base filename for the JSONL log.
    max_size_bytes : int
        File size threshold that triggers rotation.
    """

    def __init__(
        self,
        output_dir: str = DEFAULT_OUTPUT_DIR,
        filename: str = DEFAULT_FILENAME,
        max_size_bytes: int = DEFAULT_MAX_SIZE_BYTES,
    ) -> None:
        self._output_dir = output_dir
        self._filename = filename
        self._max_size_bytes = max_size_bytes
        self._lock = threading.Lock()

        # Counters
        self._total_records = 0
        self._records_by_category: Dict[str, int] = {}

        # Ensure output directory exists
        os.makedirs(self._output_dir, exist_ok=True)

    # -- public API ----------------------------------------------------------

    @property
    def filepath(self) -> str:
        """Current active log file path."""
        return os.path.join(self._output_dir, self._filename)

    def capture(
        self,
        instruction: str,
        response: str,
        category: str = "general",
        metadata: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """Capture an SFT training record and append to JSONL.

        Returns the record dict that was written.
        """
        record: Dict[str, Any] = {
            "id": f"sft-{category}-{uuid.uuid4().hex[:12]}",
            "category": category,
            "instruction": instruction,
            "response": response,
            "metadata": {
                "source": "sft_collector",
                "timestamp": time.time(),
                **(metadata or {}),
            },
        }

        line = json.dumps(record, ensure_ascii=False) + "\n"

        with self._lock:
            self._maybe_rotate()
            with open(self.filepath, "a", encoding="utf-8") as fh:
                fh.write(line)
            self._total_records += 1
            self._records_by_category[category] = (
                self._records_by_category.get(category, 0) + 1
            )

        return record

    def stats(self) -> Dict[str, Any]:
        """Return collector statistics."""
        with self._lock:
            file_size = 0
            if os.path.exists(self.filepath):
                file_size = os.path.getsize(self.filepath)

            return {
                "total_records": self._total_records,
                "by_category": dict(self._records_by_category),
                "file_path": self.filepath,
                "file_size_bytes": file_size,
                "file_size_mb": round(file_size / (1024 * 1024), 3),
                "max_size_mb": round(self._max_size_bytes / (1024 * 1024), 3),
            }

    def export(self, fmt: str = "jsonl") -> str:
        """Export collected data.

        Parameters
        ----------
        fmt : str
            ``"jsonl"`` — returns the filepath of the current JSONL file.
            ``"hf"`` — returns a HuggingFace-compatible JSONL path
                       (copies to ``sft_saas_live_hf.jsonl`` with only
                       instruction/response/category fields).

        Returns
        -------
        str
            Path to the exported file.
        """
        if fmt == "jsonl":
            return self.filepath

        if fmt == "hf":
            hf_path = os.path.join(
                self._output_dir,
                self._filename.replace(".jsonl", "_hf.jsonl"),
            )
            with self._lock:
                if not os.path.exists(self.filepath):
                    return hf_path
                with open(self.filepath, "r", encoding="utf-8") as src, \
                     open(hf_path, "w", encoding="utf-8") as dst:
                    for line in src:
                        line = line.strip()
                        if not line:
                            continue
                        try:
                            rec = json.loads(line)
                        except json.JSONDecodeError:
                            continue
                        hf_rec = {
                            "instruction": rec.get("instruction", ""),
                            "output": rec.get("response", ""),
                            "category": rec.get("category", "general"),
                        }
                        dst.write(json.dumps(hf_rec, ensure_ascii=False) + "\n")
            return hf_path

        raise ValueError(f"Unsupported export format: {fmt!r}. Use 'jsonl' or 'hf'.")

    # -- internal helpers ----------------------------------------------------

    def _maybe_rotate(self) -> None:
        """Rotate the log file if it exceeds the size threshold.

        Must be called while holding ``self._lock``.
        """
        if not os.path.exists(self.filepath):
            return
        if os.path.getsize(self.filepath) < self._max_size_bytes:
            return

        # Rename current file with a timestamp + counter suffix.
        # On Windows os.rename raises FileExistsError if the target exists,
        # so we append a monotonic counter to guarantee uniqueness.
        ts = time.strftime("%Y%m%d_%H%M%S")
        base, ext = os.path.splitext(self._filename)
        counter = 0
        while True:
            suffix = f"_{ts}" if counter == 0 else f"_{ts}_{counter}"
            rotated_name = f"{base}{suffix}{ext}"
            rotated_path = os.path.join(self._output_dir, rotated_name)
            if not os.path.exists(rotated_path):
                break
            counter += 1
        os.rename(self.filepath, rotated_path)


# ---------------------------------------------------------------------------
#  Module-level singleton
# ---------------------------------------------------------------------------

sft_collector = SFTCollector()
